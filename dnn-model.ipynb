{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3667213,"sourceType":"datasetVersion","datasetId":2195166}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2024-08-07T14:10:05.582289Z","iopub.execute_input":"2024-08-07T14:10:05.583033Z","iopub.status.idle":"2024-08-07T14:10:18.865760Z","shell.execute_reply.started":"2024-08-07T14:10:05.582999Z","shell.execute_reply":"2024-08-07T14:10:18.864715Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting split-folders\n  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split-folders\nSuccessfully installed split-folders-0.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import splitfolders\n\ndata_d = '/kaggle/input/driver-drowsiness-dataset-ddd/Driver Drowsiness Dataset (DDD)'\noutput_d = '/kaggle/working/splitted_Data'\nsplitfolders.ratio(data_d, output=output_d, seed=1942, ratio=(.8, .15, .05))","metadata":{"execution":{"iopub.status.busy":"2024-08-07T14:10:38.797673Z","iopub.execute_input":"2024-08-07T14:10:38.798620Z","iopub.status.idle":"2024-08-07T14:17:58.738044Z","shell.execute_reply.started":"2024-08-07T14:10:38.798562Z","shell.execute_reply":"2024-08-07T14:17:58.737186Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Copying files: 41793 files [07:19, 95.00 files/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"train = \"/kaggle/working/splitted_Data/train\"\ntest = \"/kaggle/working/splitted_Data/test\"\nvalidation = \"/kaggle/working/splitted_Data/val\"","metadata":{"execution":{"iopub.status.busy":"2024-08-07T14:19:20.633875Z","iopub.execute_input":"2024-08-07T14:19:20.634223Z","iopub.status.idle":"2024-08-07T14:19:20.638398Z","shell.execute_reply.started":"2024-08-07T14:19:20.634196Z","shell.execute_reply":"2024-08-07T14:19:20.637449Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\n \ninput_shape = (224, 224, 1)\n \nbase_dnn_model = Sequential()\n# Flatten the input image to 1D\nbase_dnn_model.add(Flatten(input_shape=input_shape))\n   \n # First dense layer\nbase_dnn_model.add(Dense(128, activation='relu'))\n   \n# Second dense layer\nbase_dnn_model.add(Dense(64, activation='relu'))\n \n# Third hidden layer\nbase_dnn_model.add(Dense(32, activation='relu'))\n   \n# Output layer for binary classification\nbase_dnn_model.add(Dense(1, activation='sigmoid'))\n   \n# Compile the model\nbase_dnn_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n \nbase_dnn_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:47:26.582512Z","iopub.execute_input":"2024-08-07T15:47:26.583215Z","iopub.status.idle":"2024-08-07T15:47:26.652445Z","shell.execute_reply.started":"2024-08-07T15:47:26.583182Z","shell.execute_reply":"2024-08-07T15:47:26.651608Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,422,656\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,656</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,433,025\u001b[0m (24.54 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,433,025</span> (24.54 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,433,025\u001b[0m (24.54 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,433,025</span> (24.54 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_function(img):\n    img_array = img.astype('uint8')\n    img_array = cv2.GaussianBlur(img_array, (5, 5), 0)\n    img_array = img_array / 255.0\n    img_array = np.expand_dims(img_array, axis=-1)\n    return img_array\n\n# Initiate data generators with the custom preprocessing function\ntrain_data_gen = ImageDataGenerator(preprocessing_function=preprocess_function, \n                                    rotation_range=10,\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1,\n                                    zoom_range=0.1)\nval_data_gen = ImageDataGenerator(preprocessing_function=preprocess_function)\ntest_data_gen = ImageDataGenerator(preprocessing_function=preprocess_function)\n\n# Create the generators\ntrain_generator = train_data_gen.flow_from_directory(\n    train_dir,\n    target_size=(224,224),\n    batch_size=32,\n    color_mode='grayscale', \n    class_mode='binary'  \n)\n\nval_generator = val_data_gen.flow_from_directory(\n    val_dir,\n    target_size=(224,224),\n    batch_size=32,\n    color_mode='grayscale',\n    class_mode='binary',\n    shuffle = False\n)\n\ntest_generator = test_data_gen.flow_from_directory(\n    test_dir,\n    target_size=(224,224),\n    batch_size=32,\n    color_mode='grayscale',\n    class_mode='binary',\n    shuffle=False\n)\n\n# Add EarlyStopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model with early stopping\nbase_history = base_dnn_model.fit(train_generator, validation_data=val_generator, epochs=50, callbacks=[early_stopping])\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = base_dnn_model.evaluate(test_generator)\nprint(f'Test loss: {test_loss}')\nprint(f'Test accuracy: {test_accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-08-07T15:47:50.919856Z","iopub.execute_input":"2024-08-07T15:47:50.920520Z","iopub.status.idle":"2024-08-07T16:52:28.574482Z","shell.execute_reply.started":"2024-08-07T15:47:50.920490Z","shell.execute_reply":"2024-08-07T16:52:28.573632Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Found 33434 images belonging to 2 classes.\nFound 6268 images belonging to 2 classes.\nFound 2091 images belonging to 2 classes.\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 246ms/step - accuracy: 0.6224 - loss: 1.0164 - val_accuracy: 0.8789 - val_loss: 0.2951\nEpoch 2/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 246ms/step - accuracy: 0.8475 - loss: 0.3514 - val_accuracy: 0.9813 - val_loss: 0.0798\nEpoch 3/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 244ms/step - accuracy: 0.9112 - loss: 0.2257 - val_accuracy: 0.9697 - val_loss: 0.0977\nEpoch 4/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 245ms/step - accuracy: 0.9213 - loss: 0.1989 - val_accuracy: 0.9767 - val_loss: 0.0789\nEpoch 5/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 244ms/step - accuracy: 0.9431 - loss: 0.1519 - val_accuracy: 0.9813 - val_loss: 0.0620\nEpoch 6/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 245ms/step - accuracy: 0.9500 - loss: 0.1434 - val_accuracy: 0.9925 - val_loss: 0.0263\nEpoch 7/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 244ms/step - accuracy: 0.9654 - loss: 0.1006 - val_accuracy: 0.9799 - val_loss: 0.0564\nEpoch 8/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 243ms/step - accuracy: 0.9619 - loss: 0.1084 - val_accuracy: 0.9944 - val_loss: 0.0293\nEpoch 9/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 244ms/step - accuracy: 0.9717 - loss: 0.0876 - val_accuracy: 0.9938 - val_loss: 0.0237\nEpoch 10/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 245ms/step - accuracy: 0.9718 - loss: 0.0834 - val_accuracy: 0.9930 - val_loss: 0.0213\nEpoch 11/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 243ms/step - accuracy: 0.9711 - loss: 0.0836 - val_accuracy: 0.9799 - val_loss: 0.0668\nEpoch 12/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 243ms/step - accuracy: 0.9772 - loss: 0.0724 - val_accuracy: 0.9939 - val_loss: 0.0263\nEpoch 13/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 252ms/step - accuracy: 0.9779 - loss: 0.0619 - val_accuracy: 0.9927 - val_loss: 0.0253\nEpoch 14/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 245ms/step - accuracy: 0.9775 - loss: 0.0692 - val_accuracy: 0.9927 - val_loss: 0.0277\nEpoch 15/50\n\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 245ms/step - accuracy: 0.9792 - loss: 0.0665 - val_accuracy: 0.9914 - val_loss: 0.0284\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - accuracy: 0.9889 - loss: 0.0314\nTest loss: 0.02455250360071659\nTest accuracy: 0.9918699264526367\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n \n# Initialize the data generator for validation data\nvalid_datagen = ImageDataGenerator(rescale=1 / 255.0)\n \nvalid_generator = valid_datagen.flow_from_directory(\n    directory=\"/kaggle/working/splitted_Data/val\",\n    target_size=(224, 224),\n    color_mode=\"grayscale\",\n    class_mode=\"binary\",\n    batch_size=32,\n    shuffle=False\n)\n \nsteps_per_epoch = np.ceil(valid_generator.samples / valid_generator.batch_size).astype(int)\n \n# Get predictions from the model\npredictions = base_dnn_model.predict(valid_generator, steps=steps_per_epoch)\n \n# Since this is a binary classification, we threshold predictions at 0.5\npredicted_classes = (predictions > 0.5).astype(int).reshape(-1)\n \n# Get the true classes\ntrue_classes = valid_generator.classes\n \n# Print the confusion matrix\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(true_classes, predicted_classes))\n \n# Print the classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_classes, predicted_classes, target_names=list(valid_generator.class_indices.keys())))","metadata":{"execution":{"iopub.status.busy":"2024-08-07T16:58:21.789793Z","iopub.execute_input":"2024-08-07T16:58:21.790463Z","iopub.status.idle":"2024-08-07T16:58:38.874685Z","shell.execute_reply.started":"2024-08-07T16:58:21.790431Z","shell.execute_reply":"2024-08-07T16:58:38.873817Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 6268 images belonging to 2 classes.\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 84ms/step\nConfusion Matrix:\n[[3339   13]\n [  33 2883]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Drowsy       0.99      1.00      0.99      3352\n  Non Drowsy       1.00      0.99      0.99      2916\n\n    accuracy                           0.99      6268\n   macro avg       0.99      0.99      0.99      6268\nweighted avg       0.99      0.99      0.99      6268\n\n","output_type":"stream"}]}]}